{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## running with python 3.8.5\n",
    "# installed packages are listed in train_requirements.txt\n",
    "import pandas as pd\n",
    "import time, os, sys\n",
    "from urllib.parse import urlparse\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import glob\n",
    "import re\n",
    "from tifffile import TiffFile\n",
    "import tifffile as TIFFfile\n",
    "import skimage\n",
    "import random\n",
    "import copy\n",
    "import scipy\n",
    "import scipy.ndimage\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cellpose\n",
    "from cellpose import models, utils, io\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# typical size of cells/nuclei in Âµm\n",
    "diam_um = 3.5 \n",
    "\n",
    "# train from this model:\n",
    "pretrainedModel='./pretrainedModels/cyto2torch_0' ## downloaded from https://www.cellpose.org/models/cyto2torch_0\n",
    "\n",
    "# Parameters for training:\n",
    "# number of augmentations (we used 0 or 10 (recommended) in the manuscript)\n",
    "n_augmentations= 10 \n",
    "# csv files listing all ground truth data and corresponding pixel sizes\n",
    "TrainDataFiles = \"./trainingData/TrainDataFiles.csv\"\n",
    "# retrained model files will be saved in this folder:\n",
    "OutFolder=\"./retrained_models\"\n",
    "\n",
    "# jaccard index is calculated for test data without or with blurring by factor:\n",
    "test_blur=2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Load and rescale training data\n",
    "list_traindata= pd.read_csv(TrainDataFiles)\n",
    "\n",
    "data=[]\n",
    "labels=[]\n",
    "\n",
    "list_traindata\n",
    "for i,f in enumerate(list_traindata['PathToFile']):\n",
    "    #print(i)\n",
    "    img=io.imread(f)\n",
    "    ll=io.imread(list_traindata['PathToMask'][i])\n",
    "    xscale=list_traindata['xScale'][i] * 30/diam_um\n",
    "    yscale=list_traindata['yScale'][i]  * 30/diam_um\n",
    "    imgshape=list_traindata['type'][i]\n",
    "    if xscale > 1:\n",
    "        #print('wrong')\n",
    "        img_scaled = scipy.ndimage.zoom(img,(xscale,yscale), order=3)\n",
    "    else: \n",
    "        img_scaled = scipy.ndimage.zoom(img,(xscale,yscale), order=2)\n",
    "        \n",
    "    l_scaled=scipy.ndimage.zoom(ll,(xscale,yscale), order=0)\n",
    "    \n",
    "                \n",
    "    data.append(np.uint16(img_scaled))\n",
    "    labels.append(np.uint16(l_scaled))\n",
    "        \n",
    "\n",
    "\n",
    "### Split data into test and training data\n",
    "train_data, test_data, train_label, test_label = train_test_split(data, labels,random_state=666,test_size=0.1)\n",
    "print('length of training data: ' + str(len(train_data)))\n",
    "print('length of test data: ' + str(len(test_data)))\n",
    "\n",
    "train_data_augmented = copy.deepcopy(train_data)\n",
    "train_label_augmented = copy.deepcopy(train_label)\n",
    "\n",
    "\n",
    "### Blur testdata by blurfactor_testb\n",
    "test_data_blurred = copy.deepcopy(test_data)\n",
    "for i in range(len(test_data)):\n",
    "    test_data_blurred[i] = cv2.GaussianBlur(test_data_blurred[i],(0,0),test_blur,cv2.BORDER_DEFAULT)\n",
    "\n",
    "random.seed(24579)\n",
    "if n_augmentations > 0:\n",
    "    for ii in range(n_augmentations):\n",
    "        #print(ii)\n",
    "        for i in range(len(train_data)):\n",
    "            img=np.copy(train_data[i])\n",
    "            l= np.copy(train_label[i])\n",
    "\n",
    "            # get angle for rotation (see below)\n",
    "            angle=(random.random())*45\n",
    "\n",
    "            # random flipping of images\n",
    "            if(random.random()>0.5):\n",
    "                img=np.transpose(img,(1,0))\n",
    "                l=np.transpose(l,(1,0))\n",
    "            if(random.random()>=0.5):\n",
    "                img=np.fliplr(img)\n",
    "                l=np.fliplr(l)\n",
    "            if(random.random()>=0.5):\n",
    "                img=np.flipud(img)\n",
    "                l=np.flipud(l)\n",
    "\n",
    "            # rotate image by angle (from above)\n",
    "            minI=np.amin(img)\n",
    "            img=minI+scipy.ndimage.rotate(img-minI, angle, axes=(1, 0), reshape=True, order=3, mode='constant', cval=0.0, prefilter=True)\n",
    "            l_out=scipy.ndimage.rotate(l, angle, axes=(1, 0), reshape=True, order=0, mode='constant', cval=0.0, prefilter=True)\n",
    "\n",
    "\n",
    "            # add noise\n",
    "            img_noise=skimage.util.random_noise(img/np.amax(img), 'gaussian',clip=True)\n",
    "\n",
    "            noiseratio=random.random()\n",
    "            img_out=img*(1-noiseratio) + noiseratio*img_noise*np.amax(img)\n",
    "\n",
    "            # add blurring (up to factor 3)\n",
    "            augBlur=random.random()*3\n",
    "            img_blur=cv2.GaussianBlur(img_out,(0,0),augBlur,cv2.BORDER_DEFAULT)\n",
    "\n",
    "            # increase/decrease intensity by random factoe\n",
    "            intFactor=random.random()+0.5\n",
    "            train_data_augmented.append(np.uint16(img_blur*intFactor))\n",
    "            train_label_augmented.append(np.uint16(l_out))\n",
    "\n",
    "print('augmentation done')\n",
    "print('saving to ' + 'cellpose_meioticNuclei_'+str(n_augmentations)+'Augm')\n",
    "print('number of images:')\n",
    "print(len(train_data_augmented)) \n",
    "#print(len(train_label_augmented))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model3D = models.CellposeModel(gpu=True,diam_mean=30,pretrained_model=pretrainedModel)\n",
    "chan = [0,0] # only single color images here\n",
    "\n",
    "## 500 Epochs \n",
    "modelout = model3D.train(\n",
    "              train_data_augmented, train_label_augmented,\n",
    "              test_data=test_data,test_labels=test_label, \n",
    "              channels=chan, \n",
    "              normalize=True, \n",
    "              save_path=OutFolder, model_name='cellpose500epochs_meioticNuclei_'+str(n_augmentations)+'Augm',\n",
    "              save_every=20, learning_rate=0.05, min_train_masks=2,\n",
    "              n_epochs=500, momentum=0.9, weight_decay=1e-05, batch_size=8, rescale=True)\n",
    "\n",
    "\n",
    "\n",
    "print(modelout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "masks_pred, flows, styles = model3D.eval(test_data, diameter=30, \n",
    "                                                      channels=chan, \n",
    "                                                      batch_size=3,\n",
    "                                                      normalize=True,rescale=True)\n",
    "masks_pred_blur, flows_blur, styles_blur = model3D.eval(test_data_blurred, diameter=30, \n",
    "                                                      channels=chan, \n",
    "                                                      batch_size=3,\n",
    "                                                      normalize=True,rescale=True)\n",
    "\n",
    "metrics= cellpose.metrics.aggregated_jaccard_index(test_label, masks_pred)\n",
    "metrics_blurred= cellpose.metrics.aggregated_jaccard_index(test_label, masks_pred_blur)\n",
    "\n",
    "print('processed:  cellpose500epochs_meioticNuclei_'+str(n_augmentations)+'Augm')\n",
    "print('Summary of jaccard index (no blurring): ')\n",
    "print('min: ' + str(np.amin(metrics)))\n",
    "print('mean: ' + str(np.mean(metrics)))\n",
    "print('max: ' + str(np.amax(metrics)))\n",
    "\n",
    "print('Summary of jaccard index (with blurring by ' + str(test_blur) + '): ')\n",
    "print('min: ' + str(np.amin(metrics_blurred)))\n",
    "print('mean: ' + str(np.mean(metrics_blurred)))\n",
    "print('max: ' + str(np.amax(metrics_blurred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
